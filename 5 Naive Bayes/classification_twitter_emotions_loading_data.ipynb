{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Classifiers comparison on texts with naive Bayes assumption\n",
    "\n",
    "In this session of laboratory we compare two models for categorical data probabilistic modeling: \n",
    "1. multivariate Bernoulli \n",
    "2. multinomial on a dataset \n",
    "\n",
    "We adopt a dataset on Twitter messages labelled with emotions (Joy vs Sadness).\n",
    "\n",
    "The following program shows the loading of the data from a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are loaded into a matrix X adopting a sparse matrix representation, in order to save space and time.\n",
    "Sparse matrix representation (in the csr format) represents in three \"parallel\" arrays the value of the matrix cells that are different from zero and the indices of those matrix cells.\n",
    "The arrays are called: \n",
    "- data\n",
    "- row\n",
    "- col\n",
    "\n",
    "- data[i] stores the value of the matrix cell #i whose indexes are contained in row[i] and col[i] \n",
    "- row[i] stores the index of the row in the matrix of the cell #i, \n",
    "- col[i] stores the index of the column of the cell #i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file is in csv format.\n",
    "Any Twitter message has been preprocessed by a Natural Language pipeline which eliminated stop words and substituted the interesting document elements with an integer identifier.  \n",
    "The interesting document elements might be words, emoji or emoticons. The elements could be repeated in the same document and are uniquely identified in the documents by the same integer number.\n",
    "\n",
    "Each row of the dataset is a list of integer number pairs, followed by a string which is the label of the document (Joy or sadness).\n",
    "The first number of the pair is an identifier of an element (word, emoji or emoticon) and the second number of the pair is the count (frequency) of that element in that document.\n",
    "\n",
    "The dataset has:\n",
    "tot_n_docs=n_rows=11981\n",
    "n_features (document elements)=11288\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following program reads the data file and loads in a sparse way the matrix using the scipy.sparse library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "final n_row=[          0           0           0 ... -1071380743  -937433930\n -1071524741]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "row index exceeds matrix dimensions",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1cadf0637134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"final n_row=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# loads the matrix by means of the indexes and the values in the three arrays just filled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"resulting matrix:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[1;31m# (data, ij) format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                     \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'row index exceeds matrix dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'column index exceeds matrix dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: row index exceeds matrix dimensions"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import ndarray, zeros\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class_labels = [\"Joy\",\"Sadness\"]\n",
    "n_features=11288 # number of columns in the matrix = number of features (distinct elements in the documents)\n",
    "n_rows=11981 # number rows of the matrix\n",
    "n_elements=71474 # number of the existing values in the matrix (not empty, to be loaded in the matrix in a sparse way)\n",
    "\n",
    "#path_training=\"/Users/meo/Documents/Didattica/Laboratorio-15-16-Jupyter/\"\n",
    "path_training=\"./\"\n",
    "file_name=\"joy_sadness6000.txt\"\n",
    "\n",
    "# declare the row and col arrays with the indexes of the matrix cells (non empty) to be loaded from file\n",
    "# they are needed because the matrix is sparse and we load in the matrix only the elements which are present\n",
    "row=np.empty(n_elements, dtype=int)\n",
    "col=np.empty(n_elements, dtype=int)\n",
    "data=np.empty(n_elements, dtype=int)\n",
    "\n",
    "row_n=0 # number of current row to be read and managed\n",
    "cur_el=0 # position in the arrays row, col and data\n",
    "twitter_labels=[] # list of class labels (target array) of the documents (twitter) that will be read from the input file\n",
    "twitter_target=[] # list of 0/1 for class labels\n",
    "with open(path_training + file_name, \"r\") as fi:\n",
    "    for line in fi:\n",
    "        el_list=line.split(',')\n",
    "        l=len(el_list)\n",
    "        last_el=el_list[l-1] # I grab the last element in the list which is the class label\n",
    "        class_name=last_el.strip() # eliminate the '\\n'\n",
    "        twitter_labels.append(class_name)\n",
    "        # twitter_labels contains the labels (Joy/Sadness); twitter_target contains 0/1 for the respective labels\n",
    "        if (class_name==class_labels[0]):\n",
    "           twitter_target.append(0)\n",
    "        else:\n",
    "           twitter_target.append(1)\n",
    "        i=0 # I start reading all the doc elements from the beginning of the list\n",
    "        while(i<(l-1)):\n",
    "            element_id=int(el_list[i]) # identifier of the element in the document\n",
    "            element_id=element_id-1 # the index starts from 0 (the read id starts from 1)\n",
    "            i=i+1\n",
    "            value_cell=int(el_list[i]) # make access to the following value in the file which is the count of the element in the documento \n",
    "            i=i+1\n",
    "            row[cur_el]=row_n # load the data in the three arrays: the first two are the row and col indexes; the last one is the matrix cell value\n",
    "            col[cur_el]=element_id\n",
    "            data[cur_el]=value_cell\n",
    "            cur_el=cur_el+1\n",
    "        row_n=row_n+1\n",
    "fi.close\n",
    "print(\"final n_row=\"+str(row))\n",
    "# loads the matrix by means of the indexes and the values in the three arrays just filled\n",
    "twitter_data=csr_matrix((data, (row, col)), shape=(n_rows, n_features)).toarray()\n",
    "print(\"resulting matrix:\")\n",
    "print(twitter_data)\n",
    "print(twitter_labels)\n",
    "print(twitter_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write a program in the following cell that splits the data matrix in training and test set (by random selection) and predicts the class (Joy/Sadness) of the messages on the basis of the words. \n",
    "Consider the two possible models:\n",
    "multivariate Bernoulli and multinomial Bernoulli.\n",
    "Find the accuracy of the models and test is the observed differences are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MULTIVARIATE BERNOULLI MODEL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(twitter_data, twitter_target, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# INIT MODEL\n",
    "mvariate = BernoulliNB()\n",
    "mvariate.fit(X_train,y_train)\n",
    "score = mvariate.score(X_test,y_test)\n",
    "print(\"ACCURACY OF MULTI VARIATE BERNOULLI MODEL \",score)\n",
    "\n",
    "# TRY TO PREDICT A EXAMPLE\n",
    "predicted_mvariate = mvariate.predict(X_test[0:10])\n",
    "print(predicted_mvariate)\n",
    "print(y_test[0:10])\n",
    "print(\"THE MODEL FAIL ONE TIME ( nel penultimo)\")\n",
    "\n",
    "\n",
    "# MULTINOMIAL BERNOULLI MODEL\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnomial = MultinomialNB()\n",
    "mnomial.fit(X_train,y_train)\n",
    "score = mnomial.score(X_test,y_test)\n",
    "print(\"ACCURACY OF MULTI NOMIAL BERNOULLI MODEL \",score)\n",
    "\n",
    "# TRY TO PREDICT A EXAMPLE\n",
    "predicted_mnomial= mnomial.predict(X_test[0:10])\n",
    "print(predicted_mnomial)\n",
    "print(y_test[0:10])\n",
    "print(\"THE MODEL FAIL ONE TIME ( nel penultimo anche qui)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY TO CALCULATE PERFORM OF MODELS\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "scores_mvariate = cross_val_score(mvariate,twitter_data,twitter_target,cv=10)\n",
    "scores_mnomial = cross_val_score(mnomial,twitter_data,twitter_target,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}